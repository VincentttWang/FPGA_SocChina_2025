### 11.17

- å½­å˜‰äº®ï¼šFFT IPæ ¸å¼€å‘(ç ”ç©¶ã€ç§»æ¤fftç®—å­ï¼Œè½¯ä»¶éªŒè¯)
- ç‹ä½³å®ï¼šå¯¹ç°æœ‰é™å™ªç®—æ³•è¿›è¡Œé‡æ„ï¼Œå°è¯•ç§»æ¤ï¼Œç”Ÿæˆipæ ¸

æ³¨æ„ï¼šæ¥å£å¯¹åº”å¥½ï¼ŒåŠæ—¶æ±‡æŠ¥èµ„æºå ç”¨ç‡å’Œæ˜¯å¦å¯éªŒè¯æ­£ç¡®æ€§

### 11.18

- å½­å˜‰äº®ï¼šå¯¹ç…§ç½‘ä¸Šâ€œFPGAå®æ—¶é¢‘è°±åˆ†æä»ªâ€çš„æ•°æ®ç§ç±»ï¼Œå°è¯•æ„å»ºå®æ—¶çš„PL--PSé€šé“ï¼Œä½¿éŸ³é¢‘æ•°æ®ï¼ˆå®æ—¶æµå¼ï¼‰å¯ä»¥é€šè¿‡PSç«¯è¾“å…¥ï¼Œç”Ÿæˆæ•°æ®èƒ½é€šè¿‡PSç«¯è¾“å‡ºã€åˆ©ç”¨ï¼ˆæµå¼ï¼Ÿé€Ÿåº¦ï¼Ÿï¼‰
- ç‹ä½³å®ï¼šç»§ç»­ç§»æ¤é™å™ªç®—æ³•ï¼›å®Œå–„PSç«¯è¾“å…¥è¾“å‡ºã€UIä»£ç 

### 11.19

- è”è°ƒï¼Œå†™jupyterï¼Œå°è¯•çƒ§å½•ç¬¬ä¸€ç‰ˆç¨‹åºï¼ˆé¢‘è°±åˆ†æä»ª+é™å™ªï¼‰









# ğŸ¯æ™ºèƒ½éŸ³é¢‘å¢å¼ºä¸åˆ†æç³»ç»Ÿ - 10å¤©åŒäººå¼€å‘è®¡åˆ’

**å½“å‰æ—¶é—´ï¼š** 2025-11-17 02:50 (UTC)  
**æˆªæ­¢æ—¶é—´ï¼š** 2025-11-27 02:50 (UTC)  
**å›¢é˜Ÿé…ç½®ï¼š** 2äºº  
**ç›®æ ‡ï¼š** åœ¨ PYNQ-Z2 ä¸Šå®ç°å®Œæ•´çš„æ™ºèƒ½éŸ³é¢‘å¢å¼ºç³»ç»Ÿ

---

## ğŸ“Š ç³»ç»Ÿæ¶æ„æ€»è§ˆ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          æ™ºèƒ½éŸ³é¢‘å¢å¼ºä¸åˆ†æç³»ç»Ÿ (PYNQ-Z2)                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ã€æ¨¡å—1ã€‘å®æ—¶é¢‘è°±åˆ†æä»ª (FFT)        â†’ åŸºç¡€æ¨¡å—ï¼Œä¼˜å…ˆçº§1          â”‚
â”‚  ã€æ¨¡å—2ã€‘è‡ªé€‚åº”é™å™ª (FIR + é¢‘åŸŸ)     â†’ æ ¸å¿ƒåŠŸèƒ½ï¼Œä¼˜å…ˆçº§1          â”‚
â”‚  ã€æ¨¡å—3ã€‘éŸ³é¢‘åœºæ™¯åˆ†ç±» (MFCC + ML)    â†’ AIäº®ç‚¹ï¼Œä¼˜å…ˆçº§2           â”‚
â”‚  ã€æ¨¡å—4ã€‘éŸ³è´¨å¢å¼ºå™¨ (EQ/å‹ç¼©)        â†’ é™„åŠ åŠŸèƒ½ï¼Œä¼˜å…ˆçº§3          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ‘¥ å›¢é˜Ÿåˆ†å·¥ç­–ç•¥

### **æˆå‘˜A (ç¡¬ä»¶è´Ÿè´£äºº)** - åç¡¬ä»¶/FPGA
- ğŸ”§ è´Ÿè´£ Vivado HLS IP æ ¸å¼€å‘
- ğŸ”§ è´Ÿè´£ FPGA è®¾è®¡ä¸é›†æˆ
- ğŸ”§ è´Ÿè´£ç¡¬ä»¶è°ƒè¯•ä¸ä¼˜åŒ–

### **æˆå‘˜B (è½¯ä»¶è´Ÿè´£äºº)** - åè½¯ä»¶/ç®—æ³•
- ğŸ’» è´Ÿè´£ Python é©±åŠ¨å¼€å‘
- ğŸ’» è´Ÿè´£ç®—æ³•å®ç°ä¸æ¨¡å‹è®­ç»ƒ
- ğŸ’» è´Ÿè´£ Jupyter Notebook ç•Œé¢

### **åä½œåŸåˆ™ï¼š**
- æ¯æ—¥åŒæ­¥ä¼šè®®ï¼ˆ15åˆ†é’Ÿï¼‰
- ä½¿ç”¨ Git è¿›è¡Œä»£ç ç®¡ç†
- å…³é”®èŠ‚ç‚¹äº’ç›¸ Code Review

---

## ğŸ—“ï¸ è¯¦ç»†æ—¶é—´è§„åˆ’ï¼ˆ10å¤©å†²åˆºï¼‰

---

## ğŸ“… **Day 1-2: ç¯å¢ƒæ­å»º + FFTæ ¸å¿ƒå¼€å‘** (2025-11-17 ~ 11-18)

### **æˆå‘˜Aä»»åŠ¡ï¼šæ­å»ºå¼€å‘ç¯å¢ƒ + FFT IPæ ¸**

#### **Day 1 ä¸Šåˆ (4h)ï¼šç¯å¢ƒå‡†å¤‡**
```bash
âœ… ä»»åŠ¡æ¸…å•ï¼š
â–¡ å®‰è£… Vivado HLS 2022.1+ å¹¶éªŒè¯ license
â–¡ å…‹éš† Vitis_Libraries ä»“åº“
â–¡ ç†Ÿæ‚‰ PYNQ-Z2 çº¦æŸæ–‡ä»¶
â–¡ å‡†å¤‡ SD å¡å’Œ PYNQ é•œåƒ (v3.0.1)

å…·ä½“æ“ä½œï¼š
git clone https://github.com/Xilinx/Vitis_Libraries.git
cd Vitis_Libraries/dsp/L1/src/hw/ssr_fft/

# ç ”ç©¶ç¤ºä¾‹ä»£ç 
ls -la
cat ssr_fft.h
```

#### **Day 1 ä¸‹åˆ + Day 2 ä¸Šåˆ (8h)ï¼šFFT IPæ ¸å¼€å‘**

**æ–‡ä»¶å‡†å¤‡ï¼š**
```cpp
// fft_wrapper.cpp (åˆ›å»ºç®€åŒ–ç‰ˆæœ¬)
#include <hls_stream.h>
#include <complex>
#include "ap_fixed.h"

#define FFT_SIZE 1024
typedef ap_fixed<16, 2> data_t;
typedef std::complex<data_t> complex_t;

void fft_accelerator(
    hls::stream<complex_t> &din,
    hls::stream<complex_t> &dout
) {
    #pragma HLS INTERFACE axis port=din
    #pragma HLS INTERFACE axis port=dout
    #pragma HLS INTERFACE s_axilite port=return
    
    // ä½¿ç”¨ Vitis FFT åº“æˆ–ç®€åŒ–å®ç°
    // å‚è€ƒ ssr_fft.h ä¸­çš„å®ç°
    
    complex_t buffer[FFT_SIZE];
    #pragma HLS ARRAY_PARTITION variable=buffer cyclic factor=4
    
    // è¯»å–æ•°æ®
    for(int i = 0; i < FFT_SIZE; i++) {
        #pragma HLS PIPELINE
        buffer[i] = din.read();
    }
    
    // FFT è®¡ç®— (Cooley-Tukey Radix-2)
    // TODO: å®ç°æˆ–è°ƒç”¨åº“å‡½æ•°
    
    // è¾“å‡ºç»“æœ
    for(int i = 0; i < FFT_SIZE; i++) {
        #pragma HLS PIPELINE
        dout.write(buffer[i]);
    }
}
```

**HLS å·¥ç¨‹åˆ›å»ºï¼š**
```tcl
# fft_hls.tcl
open_project fft_project
set_top fft_accelerator
add_files fft_wrapper.cpp
add_files -tb fft_test.cpp

open_solution "solution1"
set_part {xc7z020clg400-1}
create_clock -period 10 -name default

# æ¥å£é…ç½®
set_directive_interface -mode axis "fft_accelerator" din
set_directive_interface -mode axis "fft_accelerator" dout
set_directive_interface -mode s_axilite "fft_accelerator" return

# Cä»¿çœŸ
csim_design

# ç»¼åˆ
csynth_design

# C/RTL è”åˆä»¿çœŸ
cosim_design

# å¯¼å‡ºIP
export_design -format ip_catalog
```

**éªŒæ”¶æ ‡å‡†ï¼š**
- âœ… C ä»¿çœŸé€šè¿‡ï¼ˆè¯¯å·® < 1%ï¼‰
- âœ… ç»¼åˆæŠ¥å‘Šï¼šLUT < 20%, DSP < 50 ä¸ª
- âœ… å»¶è¿Ÿ < 2000 æ—¶é’Ÿå‘¨æœŸ

---

### **æˆå‘˜Bä»»åŠ¡ï¼šPythonç¯å¢ƒ + ç®—æ³•å‡†å¤‡**

#### **Day 1 (6h)ï¼šç¯å¢ƒæ­å»º**
```bash
âœ… ä»»åŠ¡æ¸…å•ï¼š
â–¡ PYNQ-Z2 ä¸Šç”µå¹¶é…ç½®ç½‘ç»œ
â–¡ å®‰è£…å¿…è¦çš„ Python åº“
â–¡ å‡†å¤‡éŸ³é¢‘æµ‹è¯•æ•°æ®é›†
â–¡ ç¼–å†™åŸºç¡€å·¥å…·å‡½æ•°

æ“ä½œæ­¥éª¤ï¼š
# SSH è¿æ¥åˆ° PYNQ-Z2
ssh xilinx@192.168.2.99  # é»˜è®¤å¯†ç ï¼šxilinx

# å®‰è£…ä¾èµ–
sudo pip3 install librosa scipy scikit-learn matplotlib soundfile

# å‡†å¤‡æ•°æ®é›†
mkdir -p ~/audio_dataset/{clean,noisy,test}
# ä¸‹è½½ ESC-50 æˆ– UrbanSound8K éƒ¨åˆ†æ ·æœ¬
```

#### **Day 2 (6h)ï¼šFFTè½¯ä»¶éªŒè¯ + é™å™ªç®—æ³•è®¾è®¡**

**FFT è½¯ä»¶å‚è€ƒå®ç°ï¼š**
```python
# fft_reference.py
import numpy as np
import matplotlib.pyplot as plt
from scipy.fft import fft, ifft

class FFTReference:
    def __init__(self, fft_size=1024, sample_rate=48000):
        self.fft_size = fft_size
        self.sr = sample_rate
    
    def analyze(self, audio):
        """é¢‘è°±åˆ†æ"""
        fft_result = fft(audio[:self.fft_size])
        magnitude = np.abs(fft_result)
        phase = np.angle(fft_result)
        freqs = np.fft.fftfreq(self.fft_size, 1/self.sr)
        return freqs[:self.fft_size//2], magnitude[:self.fft_size//2]
    
    def plot_spectrum(self, freqs, magnitude):
        """ç»˜åˆ¶é¢‘è°±å›¾"""
        plt.figure(figsize=(12, 4))
        plt.plot(freqs, 20*np.log10(magnitude + 1e-10))
        plt.xlabel('Frequency (Hz)')
        plt.ylabel('Magnitude (dB)')
        plt.title('Audio Spectrum')
        plt.grid(True)
        plt.xlim(0, self.sr/2)
        plt.show()

# æµ‹è¯•
if __name__ == "__main__":
    # ç”Ÿæˆæµ‹è¯•ä¿¡å·
    t = np.linspace(0, 1, 48000)
    test_signal = np.sin(2*np.pi*1000*t) + 0.5*np.sin(2*np.pi*3000*t)
    
    fft_ref = FFTReference()
    freqs, mags = fft_ref.analyze(test_signal)
    fft_ref.plot_spectrum(freqs, mags)
```

**é™å™ªç®—æ³•è®¾è®¡ï¼š**
```python
# noise_reduction.py
from scipy.signal import butter, lfilter, firwin

class NoiseReduction:
    def __init__(self, sample_rate=48000):
        self.sr = sample_rate
        
        # è®¾è®¡æ»¤æ³¢å™¨ç³»æ•°
        self.fir_taps = 128
        cutoff = 4000  # Hz
        self.coeffs = firwin(self.fir_taps, cutoff, fs=self.sr)
    
    def spectral_subtraction(self, noisy_audio, noise_profile):
        """é¢‘è°±å‡æ³•é™å™ª"""
        # FFT
        noisy_fft = fft(noisy_audio)
        noise_fft = fft(noise_profile)
        
        # å¹…åº¦è°±å‡æ³•
        magnitude = np.abs(noisy_fft)
        noise_mag = np.abs(noise_fft)
        
        clean_mag = np.maximum(magnitude - 2.0 * noise_mag, 0.1 * magnitude)
        
        # ä¿ç•™ç›¸ä½
        phase = np.angle(noisy_fft)
        clean_fft = clean_mag * np.exp(1j * phase)
        
        # IFFT
        clean_audio = np.real(ifft(clean_fft))
        return clean_audio
    
    def fir_filter(self, audio):
        """FIR æ»¤æ³¢å™¨é™å™ª"""
        return lfilter(self.coeffs, 1.0, audio)
```

**éªŒæ”¶æ ‡å‡†ï¼š**
- âœ… FFT è½¯ä»¶å®ç°æ­£ç¡®ï¼ˆä¸ scipy.fft ç»“æœå¯¹æ¯”ï¼‰
- âœ… é™å™ªç®—æ³•åœ¨æµ‹è¯•æ•°æ®ä¸Š SNR æå‡ > 5dB
- âœ… å‡†å¤‡å¥½è‡³å°‘ 20 ä¸ªéŸ³é¢‘æ ·æœ¬ç”¨äºæµ‹è¯•

---

## ğŸ“… **Day 3-4: FIRæ»¤æ³¢å™¨ + Vivadoé›†æˆ** (2025-11-19 ~ 11-20)

### **æˆå‘˜Aä»»åŠ¡ï¼šFIR IPæ ¸ + Block Design**

#### **Day 3 (8h)ï¼šFIRæ»¤æ³¢å™¨IPæ ¸**

```cpp
// fir_filter.cpp
#include <hls_stream.h>
#include "ap_fixed.h"

#define FIR_TAPS 128
typedef ap_fixed<16, 2> data_t;

void fir_filter(
    hls::stream<data_t> &din,
    hls::stream<data_t> &dout,
    data_t coeffs[FIR_TAPS/2]  // å¯¹ç§°ç³»æ•°
) {
    #pragma HLS INTERFACE axis port=din
    #pragma HLS INTERFACE axis port=dout
    #pragma HLS INTERFACE s_axilite port=coeffs
    #pragma HLS INTERFACE s_axilite port=return
    
    static data_t shift_reg[FIR_TAPS];
    #pragma HLS ARRAY_PARTITION variable=shift_reg cyclic factor=8
    
    data_t sample;
    din.read(sample);
    
    // ç§»ä½å¯„å­˜å™¨
    for(int i = FIR_TAPS-1; i > 0; i--) {
        #pragma HLS UNROLL factor=4
        shift_reg[i] = shift_reg[i-1];
    }
    shift_reg[0] = sample;
    
    // FIR è®¡ç®—ï¼ˆå¯¹ç§°ä¼˜åŒ–ï¼‰
    data_t acc = 0;
    for(int i = 0; i < FIR_TAPS/2; i++) {
        #pragma HLS PIPELINE II=1
        data_t sum = shift_reg[i] + shift_reg[FIR_TAPS-1-i];
        acc += sum * coeffs[i];
    }
    
    dout.write(acc);
}
```

**HLSç»¼åˆï¼š**
```tcl
open_project fir_project
set_top fir_filter
add_files fir_filter.cpp

open_solution "solution1"
set_part {xc7z020clg400-1}
create_clock -period 10

csynth_design
export_design -format ip_catalog
```

#### **Day 4 (8h)ï¼šVivado Block Design**

```tcl
# create_bd.tcl
create_project audio_system ./audio_project -part xc7z020clg400-1

# åˆ›å»º Block Design
create_bd_design "system"

# æ·»åŠ  ZYNQ PS
create_bd_cell -type ip -vlnv xilinx.com:ip:processing_system7:5.5 ps7_0

# åº”ç”¨æ¿çº§é¢„è®¾
apply_bd_automation -rule xilinx.com:bd_rule:processing_system7 \
    -config {make_external "FIXED_IO, DDR" } [get_bd_cells ps7_0]

# æ·»åŠ  FFT IP
create_bd_cell -type ip -vlnv user.org:hls:fft_accelerator:1.0 fft_0

# æ·»åŠ  FIR IP
create_bd_cell -type ip -vlnv user.org:hls:fir_filter:1.0 fir_0

# æ·»åŠ  AXI DMAï¼ˆ2ä¸ªï¼ŒFFTå’ŒFIRå„ä¸€ä¸ªï¼‰
create_bd_cell -type ip -vlnv xilinx.com:ip:axi_dma:7.1 axi_dma_fft
create_bd_cell -type ip -vlnv xilinx.com:ip:axi_dma:7.1 axi_dma_fir

# é…ç½® DMA
set_property -dict [list \
    CONFIG.c_include_sg {0} \
    CONFIG.c_sg_include_stscntrl_strm {0} \
] [get_bd_cells axi_dma_fft]

# è¿æ¥ AXI Stream
connect_bd_intf_net [get_bd_intf_pins axi_dma_fft/M_AXIS_MM2S] \
    [get_bd_intf_pins fft_0/din]
connect_bd_intf_net [get_bd_intf_pins fft_0/dout] \
    [get_bd_intf_pins axi_dma_fft/S_AXIS_S2MM]

# è¿æ¥ AXI äº’è¿
create_bd_cell -type ip -vlnv xilinx.com:ip:axi_interconnect:2.1 axi_interconnect_0
set_property -dict [list CONFIG.NUM_MI {4}] [get_bd_cells axi_interconnect_0]

# åœ°å€åˆ†é…
assign_bd_address

# éªŒè¯è®¾è®¡
validate_bd_design

# ç”Ÿæˆ HDL wrapper
make_wrapper -files [get_files system.bd] -top
add_files -norecurse [get_files */system_wrapper.v]

# ç»¼åˆå®ç°
launch_runs impl_1 -to_step write_bitstream -jobs 4
wait_on_run impl_1
```

**éªŒæ”¶æ ‡å‡†ï¼š**
- âœ… FIR IP ç»¼åˆæˆåŠŸï¼Œèµ„æºå ç”¨ < 25%
- âœ… Block Design æ— é”™è¯¯ï¼Œæ‰€æœ‰æ¥å£æ­£ç¡®è¿æ¥
- âœ… Bitstream ç”ŸæˆæˆåŠŸ

---

### **æˆå‘˜Bä»»åŠ¡ï¼šPYNQé©±åŠ¨æ¡†æ¶**

#### **Day 3-4 (16h)ï¼šPythoné©±åŠ¨å¼€å‘**

```python
# audio_system.py
from pynq import Overlay, allocate
import numpy as np
from scipy.signal import firwin

class AudioSystem:
    def __init__(self, bitstream_path='audio_system.bit'):
        """åˆå§‹åŒ–éŸ³é¢‘å¤„ç†ç³»ç»Ÿ"""
        print("Loading overlay...")
        self.overlay = Overlay(bitstream_path)
        
        # è·å–IPå¼•ç”¨
        self.fft = self.overlay.fft_0
        self.fir = self.overlay.fir_0
        self.dma_fft = self.overlay.axi_dma_fft_0
        self.dma_fir = self.overlay.axi_dma_fir_0
        
        # é…ç½®å‚æ•°
        self.fft_size = 1024
        self.fir_taps = 128
        self.sample_rate = 48000
        
        # åˆå§‹åŒ–æ»¤æ³¢å™¨ç³»æ•°
        self._init_fir_coefficients()
        
        print("System initialized successfully!")
    
    def _init_fir_coefficients(self):
        """åˆå§‹åŒ–FIRæ»¤æ³¢å™¨ç³»æ•°"""
        cutoff = 4000  # Hz
        coeffs = firwin(self.fir_taps, cutoff, fs=self.sample_rate)
        
        # å¯¹ç§°ç³»æ•°ï¼Œåªéœ€ä¸€åŠ
        sym_coeffs = coeffs[:self.fir_taps//2]
        
        # è½¬æ¢ä¸ºå®šç‚¹æ•°å¹¶å†™å…¥IP
        coeffs_fixed = (sym_coeffs * (2**14)).astype(np.int16)
        
        # å†™å…¥å¯„å­˜å™¨ï¼ˆåœ°å€éœ€è¦æ ¹æ®HLSç”Ÿæˆçš„æ˜ å°„ï¼‰
        for i, coef in enumerate(coeffs_fixed):
            self.fir.write(0x100 + i*4, int(coef))
    
    def fft_transform(self, audio_data):
        """FFT å˜æ¢"""
        # ç¡®ä¿æ•°æ®é•¿åº¦
        if len(audio_data) != self.fft_size:
            audio_data = np.resize(audio_data, self.fft_size)
        
        # åˆ†é… DMA ç¼“å†²åŒºï¼ˆå¤æ•°æ•°æ®ï¼Œ2ä¸ªfloatï¼‰
        input_buffer = allocate(shape=(self.fft_size, 2), dtype=np.float32)
        output_buffer = allocate(shape=(self.fft_size, 2), dtype=np.float32)
        
        # å‡†å¤‡è¾“å…¥æ•°æ®ï¼ˆå®éƒ¨ã€è™šéƒ¨ï¼‰
        input_buffer[:, 0] = audio_data.real
        input_buffer[:, 1] = audio_data.imag if np.iscomplexobj(audio_data) else 0
        
        # DMA ä¼ è¾“
        self.dma_fft.sendchannel.transfer(input_buffer)
        self.dma_fft.recvchannel.transfer(output_buffer)
        self.dma_fft.sendchannel.wait()
        self.dma_fft.recvchannel.wait()
        
        # æ„é€ å¤æ•°ç»“æœ
        result = output_buffer[:, 0] + 1j * output_buffer[:, 1]
        
        # é‡Šæ”¾ç¼“å†²åŒº
        input_buffer.freebuffer()
        output_buffer.freebuffer()
        
        return result
    
    def fir_denoise(self, audio_data):
        """FIR æ»¤æ³¢é™å™ª"""
        # åˆ†é…ç¼“å†²åŒº
        input_buffer = allocate(shape=(len(audio_data),), dtype=np.int16)
        output_buffer = allocate(shape=(len(audio_data),), dtype=np.int16)
        
        # è½¬æ¢ä¸ºå®šç‚¹æ•°
        audio_fixed = (audio_data * 32767).astype(np.int16)
        np.copyto(input_buffer, audio_fixed)
        
        # DMA ä¼ è¾“
        self.dma_fir.sendchannel.transfer(input_buffer)
        self.dma_fir.recvchannel.transfer(output_buffer)
        self.dma_fir.sendchannel.wait()
        self.dma_fir.recvchannel.wait()
        
        # è½¬æ¢å›æµ®ç‚¹
        result = np.array(output_buffer) / 32767.0
        
        # é‡Šæ”¾ç¼“å†²åŒº
        input_buffer.freebuffer()
        output_buffer.freebuffer()
        
        return result
    
    def spectrum_analyze(self, audio_data):
        """é¢‘è°±åˆ†æ"""
        fft_result = self.fft_transform(audio_data)
        magnitude = np.abs(fft_result)
        phase = np.angle(fft_result)
        
        # é¢‘ç‡è½´
        freqs = np.fft.fftfreq(self.fft_size, 1/self.sample_rate)
        
        return freqs[:self.fft_size//2], magnitude[:self.fft_size//2]
```

**æµ‹è¯•è„šæœ¬ï¼š**
```python
# test_hardware.py
import numpy as np
import soundfile as sf
from audio_system import AudioSystem

def test_fft():
    """æµ‹è¯•FFTåŠ é€Ÿå™¨"""
    sys = AudioSystem('audio_system.bit')
    
    # ç”Ÿæˆæµ‹è¯•ä¿¡å·
    t = np.linspace(0, 1, 48000)
    test_signal = np.sin(2*np.pi*1000*t) + 0.5*np.sin(2*np.pi*3000*t)
    
    # ç¡¬ä»¶FFT
    freqs, mags = sys.spectrum_analyze(test_signal[:1024])
    
    # è½¯ä»¶FFTå¯¹æ¯”
    fft_ref = np.fft.fft(test_signal[:1024])
    mags_ref = np.abs(fft_ref[:512])
    
    # è¯¯å·®è®¡ç®—
    error = np.mean(np.abs(mags - mags_ref))
    print(f"FFT Error: {error:.6f}")
    
    assert error < 0.01, "FFTç²¾åº¦ä¸è¶³ï¼"
    print("âœ… FFTæµ‹è¯•é€šè¿‡")

def test_fir():
    """æµ‹è¯•FIRæ»¤æ³¢å™¨"""
    sys = AudioSystem('audio_system.bit')
    
    # åŠ è½½å«å™ªéŸ³é¢‘
    audio, sr = sf.read('test_noisy.wav')
    
    # ç¡¬ä»¶æ»¤æ³¢
    filtered = sys.fir_denoise(audio[:48000])
    
    # ä¿å­˜ç»“æœ
    sf.write('test_filtered_hw.wav', filtered, sr)
    print("âœ… FIRæ»¤æ³¢æµ‹è¯•é€šè¿‡ï¼Œç»“æœå·²ä¿å­˜")

if __name__ == "__main__":
    test_fft()
    test_fir()
```

**éªŒæ”¶æ ‡å‡†ï¼š**
- âœ… FFT ç¡¬ä»¶åŠ é€Ÿä¸è½¯ä»¶ç»“æœè¯¯å·® < 1%
- âœ… FIR æ»¤æ³¢å™¨æ­£å¸¸å·¥ä½œï¼ŒéŸ³è´¨æ”¹å–„å¯å¬åˆ°
- âœ… DMA ä¼ è¾“æ— é”™è¯¯ï¼Œå»¶è¿Ÿ < 50ms

---

## ğŸ“… **Day 5-6: éŸ³é¢‘åˆ†ç±»æ¨¡å‹è®­ç»ƒ + é™å™ªä¼˜åŒ–** (2025-11-21 ~ 11-22)

### **æˆå‘˜Aä»»åŠ¡ï¼šé™å™ªç®—æ³•FPGAä¼˜åŒ–**

#### **Day 5-6 (16h)ï¼šé¢‘åŸŸé™å™ª + è‡ªé€‚åº”æ»¤æ³¢**

```cpp
// adaptive_filter.cpp
#include <hls_stream.h>
#include "ap_fixed.h"
#include <cmath>

#define BLOCK_SIZE 256
typedef ap_fixed<16, 2> data_t;

void spectral_subtraction(
    hls::stream<data_t> &noisy_real,
    hls::stream<data_t> &noisy_imag,
    hls::stream<data_t> &noise_real,
    hls::stream<data_t> &noise_imag,
    hls::stream<data_t> &clean_real,
    hls::stream<data_t> &clean_imag
) {
    #pragma HLS INTERFACE axis port=noisy_real
    #pragma HLS INTERFACE axis port=noisy_imag
    #pragma HLS INTERFACE axis port=noise_real
    #pragma HLS INTERFACE axis port=noise_imag
    #pragma HLS INTERFACE axis port=clean_real
    #pragma HLS INTERFACE axis port=clean_imag
    
    for(int i = 0; i < BLOCK_SIZE; i++) {
        #pragma HLS PIPELINE II=1
        
        // è¯»å–è¾“å…¥
        data_t nr = noisy_real.read();
        data_t ni = noisy_imag.read();
        data_t noise_r = noise_real.read();
        data_t noise_i = noise_imag.read();
        
        // è®¡ç®—å¹…åº¦
        data_t noisy_mag = sqrt(nr*nr + ni*ni);
        data_t noise_mag = sqrt(noise_r*noise_r + noise_i*noise_i);
        
        // é¢‘è°±å‡æ³•
        data_t clean_mag = (noisy_mag - 2.0f * noise_mag > 0) ? 
                           (noisy_mag - 2.0f * noise_mag) : 
                           (0.1f * noisy_mag);
        
        // ä¿æŒç›¸ä½
        data_t scale = clean_mag / (noisy_mag + 1e-10f);
        
        clean_real.write(nr * scale);
        clean_imag.write(ni * scale);
    }
}
```

**é›†æˆåˆ°ä¸»ç³»ç»Ÿï¼š**
```tcl
# åœ¨ Vivado Block Design ä¸­æ·»åŠ 
create_bd_cell -type ip -vlnv user.org:hls:spectral_subtraction:1.0 denoise_0

# è¿æ¥ FFT â†’ é™å™ª â†’ IFFT
connect_bd_intf_net [get_bd_intf_pins fft_0/dout] \
    [get_bd_intf_pins denoise_0/noisy_input]
```

---

### **æˆå‘˜Bä»»åŠ¡ï¼šéŸ³é¢‘åˆ†ç±»æ¨¡å‹**

#### **Day 5 (8h)ï¼šæ•°æ®å‡†å¤‡ + ç‰¹å¾æå–**

```python
# feature_extraction.py
import librosa
import numpy as np
from sklearn.preprocessing import StandardScaler

class AudioFeatureExtractor:
    def __init__(self, sample_rate=48000, n_mfcc=13):
        self.sr = sample_rate
        self.n_mfcc = n_mfcc
        self.scaler = StandardScaler()
    
    def extract_mfcc(self, audio):
        """æå–MFCCç‰¹å¾"""
        # MFCC
        mfcc = librosa.feature.mfcc(y=audio, sr=self.sr, n_mfcc=self.n_mfcc)
        mfcc_mean = np.mean(mfcc, axis=1)
        mfcc_std = np.std(mfcc, axis=1)
        
        # ç»Ÿè®¡ç‰¹å¾
        features = np.concatenate([mfcc_mean, mfcc_std])
        return features
    
    def extract_all_features(self, audio):
        """æå–å®Œæ•´ç‰¹å¾é›†"""
        features = []
        
        # MFCC
        mfcc = self.extract_mfcc(audio)
        features.extend(mfcc)
        
        # è¿‡é›¶ç‡
        zcr = librosa.feature.zero_crossing_rate(audio)
        features.extend([np.mean(zcr), np.std(zcr)])
        
        # é¢‘è°±è´¨å¿ƒ
        spectral_centroids = librosa.feature.spectral_centroid(y=audio, sr=self.sr)
        features.extend([np.mean(spectral_centroids), np.std(spectral_centroids)])
        
        # é¢‘è°±å¸¦å®½
        spectral_bandwidth = librosa.feature.spectral_bandwidth(y=audio, sr=self.sr)
        features.extend([np.mean(spectral_bandwidth), np.std(spectral_bandwidth)])
        
        return np.array(features)

# æ•°æ®é›†å‡†å¤‡
def prepare_dataset(data_dir='./audio_dataset'):
    """å‡†å¤‡è®­ç»ƒæ•°æ®é›†"""
    extractor = AudioFeatureExtractor()
    
    scenes = ['indoor', 'outdoor', 'meeting', 'music', 'speech', 
              'traffic', 'nature', 'machine', 'crowd', 'silence']
    
    X = []
    y = []
    
    for scene_idx, scene in enumerate(scenes):
        scene_dir = f"{data_dir}/{scene}"
        audio_files = glob.glob(f"{scene_dir}/*.wav")
        
        for audio_file in audio_files:
            audio, sr = librosa.load(audio_file, sr=48000)
            
            # åˆ†æ®µæå–ç‰¹å¾
            for i in range(0, len(audio) - 48000, 24000):
                segment = audio[i:i+48000]
                features = extractor.extract_all_features(segment)
                X.append(features)
                y.append(scene_idx)
    
    return np.array(X), np.array(y)
```

#### **Day 6 (8h)ï¼šæ¨¡å‹è®­ç»ƒ**

```python
# train_classifier.py
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
import joblib

def train_scene_classifier():
    """è®­ç»ƒåœºæ™¯åˆ†ç±»å™¨"""
    # åŠ è½½æ•°æ®
    print("Loading dataset...")
    X, y = prepare_dataset()
    
    # æ•°æ®æ ‡å‡†åŒ–
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    
    # åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
    X_train, X_test, y_train, y_test = train_test_split(
        X_scaled, y, test_size=0.2, random_state=42
    )
    
    # è®­ç»ƒéšæœºæ£®æ—
    print("Training Random Forest...")
    clf = RandomForestClassifier(
        n_estimators=100,
        max_depth=20,
        min_samples_split=5,
        random_state=42,
        n_jobs=-1
    )
    
    clf.fit(X_train, y_train)
    
    # è¯„ä¼°
    y_pred = clf.predict(X_test)
    print("\nåˆ†ç±»æŠ¥å‘Šï¼š")
    print(classification_report(y_test, y_pred))
    
    print("\næ··æ·†çŸ©é˜µï¼š")
    print(confusion_matrix(y_test, y_pred))
    
    # ä¿å­˜æ¨¡å‹
    joblib.dump(clf, 'scene_classifier.pkl')
    joblib.dump(scaler, 'feature_scaler.pkl')
    
    print("\nâœ… æ¨¡å‹è®­ç»ƒå®Œæˆå¹¶ä¿å­˜")
    
    return clf, scaler

if __name__ == "__main__":
    clf, scaler = train_scene_classifier()
```

**éªŒæ”¶æ ‡å‡†ï¼š**
- âœ… æ”¶é›†è‡³å°‘ 10 ç±»åœºæ™¯ï¼Œæ¯ç±» >= 50 ä¸ªæ ·æœ¬
- âœ… åˆ†ç±»å‡†ç¡®ç‡ > 80%
- âœ… æ¨¡å‹å¤§å° < 10MB

---

## ğŸ“… **Day 7-8: ç³»ç»Ÿé›†æˆ + Jupyterç•Œé¢** (2025-11-23 ~ 11-24)

### **æˆå‘˜Aä»»åŠ¡ï¼šæœ€ç»ˆç¡¬ä»¶é›†æˆ**

#### **Day 7 (8h)ï¼šå®Œæ•´ç³»ç»Ÿç»¼åˆ**

```tcl
# æœ€ç»ˆ Block Design æ£€æŸ¥æ¸…å•
â–¡ ZYNQ PS é…ç½®æ­£ç¡®ï¼ˆM_AXI_GP0 ä½¿èƒ½ï¼‰
â–¡ FFT IP æ­£ç¡®è¿æ¥ï¼ˆdin, dout, s_axi_controlï¼‰
â–¡ FIR IP æ­£ç¡®è¿æ¥
â–¡ é™å™ª IP æ­£ç¡®è¿æ¥
â–¡ æ‰€æœ‰ DMA é…ç½®æ­£ç¡®
â–¡ AXI Interconnect æ— æ—¶åºè¿ä¾‹
â–¡ åœ°å€æ˜ å°„æ— å†²çª

# é‡æ–°ç»¼åˆå®ç°
reset_run synth_1
launch_runs synth_1 -jobs 4
wait_on_run synth_1

launch_runs impl_1 -to_step write_bitstream -jobs 4
wait_on_run impl_1

# æ£€æŸ¥èµ„æºä½¿ç”¨
open_run impl_1
report_utilization -file utilization.txt
report_timing_summary -file timing.txt
```

**èµ„æºç›®æ ‡ï¼š**
| èµ„æº | ä½¿ç”¨    | å¯ç”¨    | åˆ©ç”¨ç‡ |
| ---- | ------- | ------- | ------ |
| LUT  | ~25,000 | 53,200  | < 50%  |
| FF   | ~30,000 | 106,400 | < 30%  |
| BRAM | 80      | 140     | < 60%  |
| DSP  | 120     | 220     | < 55%  |

#### **Day 8 (8h)ï¼šç¡¬ä»¶è°ƒè¯•**

```python
# hardware_debug.py
def debug_system():
    """ç³»ç»Ÿçº§è°ƒè¯•"""
    sys = AudioSystem('audio_system.bit')
    
    # 1. æ£€æŸ¥IPçŠ¶æ€
    print("FFT Status:", hex(sys.fft.read(0x00)))
    print("FIR Status:", hex(sys.fir.read(0x00)))
    
    # 2. å•æ­¥æµ‹è¯•
    test_signal = np.sin(2*np.pi*1000*np.linspace(0,1,1024))
    
    # FFT æµ‹è¯•
    fft_out = sys.fft_transform(test_signal)
    print("FFT Peak:", np.argmax(np.abs(fft_out)))
    
    # FIR æµ‹è¯•
    fir_out = sys.fir_denoise(test_signal)
    print("FIR Output:", fir_out[:10])
    
    # 3. ç«¯åˆ°ç«¯æµ‹è¯•
    audio, sr = sf.read('test.wav')
    
    # é¢‘è°±åˆ†æ
    freqs, mags = sys.spectrum_analyze(audio[:1024])
    
    # é™å™ª
    denoised = sys.fir_denoise(audio)
    
    # ä¿å­˜ç»“æœ
    sf.write('denoised_hw.wav', denoised, sr)
    
    print("âœ… ç³»ç»Ÿè°ƒè¯•å®Œæˆ")
```

---

### **æˆå‘˜Bä»»åŠ¡ï¼šå®Œæ•´è½¯ä»¶ç³»ç»Ÿ**

#### **Day 7-8 (16h)ï¼šé›†æˆæ‰€æœ‰åŠŸèƒ½**

```python
# complete_system.py
class CompleteAudioSystem:
    def __init__(self, bitstream_path='audio_system.bit'):
        """å®Œæ•´éŸ³é¢‘å¢å¼ºç³»ç»Ÿ"""
        # ç¡¬ä»¶
        self.hw = AudioSystem(bitstream_path)
        
        # è½¯ä»¶æ¨¡å‹
        self.classifier = joblib.load('scene_classifier.pkl')
        self.scaler = joblib.load('feature_scaler.pkl')
        self.feature_extractor = AudioFeatureExtractor()
        
        # çŠ¶æ€
        self.noise_profile = None
    
    def process_pipeline(self, audio_file):
        """å®Œæ•´å¤„ç†æµæ°´çº¿"""
        print("=" * 50)
        print("æ™ºèƒ½éŸ³é¢‘å¢å¼ºä¸åˆ†æç³»ç»Ÿ")
        print("=" * 50)
        
        # 1. åŠ è½½éŸ³é¢‘
        print("\n[1/5] åŠ è½½éŸ³é¢‘æ–‡ä»¶...")
        audio, sr = librosa.load(audio_file, sr=self.hw.sample_rate)
        print(f"   æ—¶é•¿: {len(audio)/sr:.2f}ç§’")
        
        # 2. é¢‘è°±åˆ†æ
        print("\n[2/5] é¢‘è°±åˆ†æï¼ˆç¡¬ä»¶åŠ é€Ÿï¼‰...")
        freqs, mags = self.hw.spectrum_analyze(audio[:1024])
        peak_freq = freqs[np.argmax(mags)]
        print(f"   ä¸»é¢‘: {peak_freq:.1f} Hz")
        
        # 3. åœºæ™¯è¯†åˆ«
        print("\n[3/5] åœºæ™¯è¯†åˆ«...")
        features = self.feature_extractor.extract_all_features(audio)
        features_scaled = self.scaler.transform([features])
        scene_idx = self.classifier.predict(features_scaled)[0]
        scene_prob = self.classifier.predict_proba(features_scaled)[0]
        
        scenes = ['å®¤å†…', 'å®¤å¤–', 'ä¼šè®®', 'éŸ³ä¹', 'è¯­éŸ³', 
                  'äº¤é€š', 'è‡ªç„¶', 'æœºæ¢°', 'äººç¾¤', 'å®‰é™']
        print(f"   åœºæ™¯: {scenes[scene_idx]} ({scene_prob[scene_idx]*100:.1f}%)")
        
        # 4. è‡ªé€‚åº”é™å™ª
        print("\n[4/5] è‡ªé€‚åº”é™å™ªï¼ˆç¡¬ä»¶åŠ é€Ÿï¼‰...")
        denoised = self.hw.fir_denoise(audio)
        
        # è®¡ç®—SNRæå‡
        noise = audio - denoised
        snr_before = 10 * np.log10(np.var(audio) / np.var(noise))
        print(f"   SNRæå‡: {snr_before:.1f} dB")
        
        # 5. éŸ³è´¨å¢å¼º
        print("\n[5/5] éŸ³è´¨å¢å¼º...")
        enhanced = self.enhance_audio(denoised)
        
        print("\n" + "=" * 50)
        print("å¤„ç†å®Œæˆï¼")
        print("=" * 50)
        
        return {
            'spectrum': (freqs, mags),
            'scene': scenes[scene_idx],
            'scene_confidence': scene_prob[scene_idx],
            'denoised': denoised,
            'enhanced': enhanced,
            'snr_improvement': snr_before
        }
    
    def enhance_audio(self, audio):
        """éŸ³è´¨å¢å¼ºï¼ˆEQ + å‹ç¼©ï¼‰"""
        # ç®€å•çš„3æ®µEQ
        # ä½é¢‘å¢å¼º
        low_band = self._eq_band(audio, 100, 300, gain=1.2)
        # ä¸­é¢‘
        mid_band = self._eq_band(audio, 300, 3000, gain=1.0)
        # é«˜é¢‘å¢å¼º
        high_band = self._eq_band(audio, 3000, 8000, gain=1.1)
        
        enhanced = low_band + mid_band + high_band
        
        # åŠ¨æ€èŒƒå›´å‹ç¼©
        enhanced = self._compress(enhanced, threshold=0.5, ratio=4)
        
        return enhanced
    
    def _eq_band(self, audio, low, high, gain):
        """å¸¦é€šæ»¤æ³¢ + å¢ç›Š"""
        from scipy.signal import butter, filtfilt
        sos = butter(4, [low, high], btype='band', fs=self.hw.sample_rate, output='sos')
        filtered = filtfilt(sos[0], sos[1], audio)
        return filtered * gain
    
    def _compress(self, audio, threshold, ratio):
        """åŠ¨æ€å‹ç¼©å™¨"""
        compressed = np.copy(audio)
        mask = np.abs(audio) > threshold
        compressed[mask] = np.sign(audio[mask]) * (
            threshold + (np.abs(audio[mask]) - threshold) / ratio
        )
        return compressed
```

**Jupyter Notebook ç•Œé¢ï¼š**

```python
# demo.ipynb (Jupyter Notebook)
import ipywidgets as widgets
from IPython.display import Audio, display
import matplotlib.pyplot as plt

# åˆå§‹åŒ–ç³»ç»Ÿ
system = CompleteAudioSystem('audio_system.bit')

# æ–‡ä»¶ä¸Šä¼ æ§ä»¶
uploader = widgets.FileUpload(
    accept='.wav',
    multiple=False,
    description='ä¸Šä¼ éŸ³é¢‘'
)

# å¤„ç†æŒ‰é’®
process_btn = widgets.Button(
    description='å¼€å§‹å¤„ç†',
    button_style='success'
)

# è¾“å‡ºåŒºåŸŸ
output = widgets.Output()

def on_process_clicked(b):
    with output:
        output.clear_output()
        
        # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶
        uploaded_file = list(uploader.value.values())[0]
        with open('temp.wav', 'wb') as f:
            f.write(uploaded_file['content'])
        
        # å¤„ç†
        result = system.process_pipeline('temp.wav')
        
        # å¯è§†åŒ–
        fig, axes = plt.subplots(3, 1, figsize=(12, 10))
        
        # é¢‘è°±å›¾
        axes[0].plot(result['spectrum'][0], 
                     20*np.log10(result['spectrum'][1] + 1e-10))
        axes[0].set_title('é¢‘è°±åˆ†æ')
        axes[0].set_xlabel('é¢‘ç‡ (Hz)')
        axes[0].set_ylabel('å¹…åº¦ (dB)')
        axes[0].grid(True)
        
        # æ³¢å½¢å¯¹æ¯”
        t = np.linspace(0, len(result['denoised'])/48000, len(result['denoised']))
        axes[1].plot(t[:1000], result['denoised'][:1000], label='é™å™ªå')
        axes[1].set_title('é™å™ªæ•ˆæœ')
        axes[1].set_xlabel('æ—¶é—´ (s)')
        axes[1].set_ylabel('å¹…åº¦')
        axes[1].legend()
        axes[1].grid(True)
        
        # å¢å¼ºæ•ˆæœ
        axes[2].plot(t[:1000], result['enhanced'][:1000], 'g', label='å¢å¼ºå')
        axes[2].set_title('éŸ³è´¨å¢å¼º')
        axes[2].set_xlabel('æ—¶é—´ (s)')
        axes[2].set_ylabel('å¹…åº¦')
        axes[2].legend()
        axes[2].grid(True)
        
        plt.tight_layout()
        plt.show()
        
        # éŸ³é¢‘æ’­æ”¾
        print(f"\nåœºæ™¯è¯†åˆ«: {result['scene']}")
        print(f"ç½®ä¿¡åº¦: {result['scene_confidence']*100:.1f}%")
        print(f"SNRæå‡: {result['snr_improvement']:.1f} dB")
        
        print("\nåŸå§‹éŸ³é¢‘:")
        display(Audio(data=result['denoised'], rate=48000))
        
        print("\nå¢å¼ºéŸ³é¢‘:")
        display(Audio(data=result['enhanced'], rate=48000))

process_btn.on_click(on_process_clicked)

# æ˜¾ç¤ºUI
display(uploader)
display(process_btn)
display(output)
```

**éªŒæ”¶æ ‡å‡†ï¼š**
- âœ… æ‰€æœ‰åŠŸèƒ½æ­£å¸¸è¿è¡Œ
- âœ… Jupyter ç•Œé¢å‹å¥½ï¼Œäº¤äº’æµç•…
- âœ… å¤„ç†æ—¶é—´ < 5 ç§’ï¼ˆ1åˆ†é’ŸéŸ³é¢‘ï¼‰

---

## ğŸ“… **Day 9: æµ‹è¯•ä¼˜åŒ–** (2025-11-25)

### **åŒäººåä½œï¼šå…¨é¢æµ‹è¯•**

#### **æµ‹è¯•æ¸…å•ï¼š**

```python
# comprehensive_test.py

def test_suite():
    """å®Œæ•´æµ‹è¯•å¥—ä»¶"""
    system = CompleteAudioSystem()
    
    print("å¼€å§‹ç³»ç»Ÿæµ‹è¯•...")
    print("=" * 60)
    
    # 1. åŠŸèƒ½æµ‹è¯•
    print("\n[æµ‹è¯•1] é¢‘è°±åˆ†æç²¾åº¦")
    test_fft_accuracy()
    
    print("\n[æµ‹è¯•2] é™å™ªæ•ˆæœ")
    test_denoise_quality()
    
    print("\n[æµ‹è¯•3] åœºæ™¯åˆ†ç±»å‡†ç¡®ç‡")
    test_classification()
    
    print("\n[æµ‹è¯•4] ç«¯åˆ°ç«¯å»¶è¿Ÿ")
    test_latency()
    
    print("\n[æµ‹è¯•5] èµ„æºå ç”¨")
    test_resource_usage()
    
    print("\n[æµ‹è¯•6] ç¨³å®šæ€§æµ‹è¯•")
    test_stability()
    
    print("\n" + "=" * 60)
    print("âœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")

def test_fft_accuracy():
    """FFTç²¾åº¦æµ‹è¯•"""
    # æ ‡å‡†æµ‹è¯•ä¿¡å·
    test_signals = [
        ('å•é¢‘', lambda t: np.sin(2*np.pi*1000*t)),
        ('åŒé¢‘', lambda t: np.sin(2*np.pi*1000*t) + np.sin(2*np.pi*3000*t)),
        ('æ‰«é¢‘', lambda t: np.sin(2*np.pi*np.linspace(100, 8000, len(t))*t))
    ]
    
    for name, sig_func in test_signals:
        t = np.linspace(0, 1, 1024)
        signal = sig_func(t)
        
        # ç¡¬ä»¶ vs è½¯ä»¶
        hw_fft = system.hw.fft_transform(signal)
        sw_fft = np.fft.fft(signal)
        
        error = np.mean(np.abs(hw_fft - sw_fft))
        print(f"   {name}: è¯¯å·® = {error:.6f}")
        assert error < 0.01, f"{name}æµ‹è¯•å¤±è´¥"

def test_denoise_quality():
    """é™å™ªè´¨é‡æµ‹è¯•"""
    # åŠ è½½æµ‹è¯•éŸ³é¢‘
    test_files = glob.glob('test_data/noisy_*.wav')
    
    snr_improvements = []
    
    for file in test_files:
        audio, sr = librosa.load(file, sr=48000)
        denoised = system.hw.fir_denoise(audio)
        
        # è®¡ç®—SNR
        noise = audio - denoised
        snr = 10 * np.log10(np.var(audio) / np.var(noise))
        snr_improvements.append(snr)
    
    avg_snr = np.mean(snr_improvements)
    print(f"   å¹³å‡SNRæå‡: {avg_snr:.2f} dB")
    assert avg_snr > 5, "é™å™ªæ•ˆæœä¸è¶³"

def test_classification():
    """åˆ†ç±»å‡†ç¡®ç‡æµ‹è¯•"""
    # åŠ è½½æµ‹è¯•é›†
    X_test, y_test = load_test_dataset()
    
    predictions = system.classifier.predict(X_test)
    accuracy = np.mean(predictions == y_test)
    
    print(f"   å‡†ç¡®ç‡: {accuracy*100:.1f}%")
    assert accuracy > 0.8, "åˆ†ç±»å‡†ç¡®ç‡è¿‡ä½"

def test_latency():
    """å»¶è¿Ÿæµ‹è¯•"""
    import time
    
    audio = np.random.randn(48000)  # 1ç§’éŸ³é¢‘
    
    start = time.time()
    result = system.process_pipeline_fast(audio)
    end = time.time()
    
    latency = (end - start) * 1000  # ms
    print(f"   ç«¯åˆ°ç«¯å»¶è¿Ÿ: {latency:.1f} ms")
    assert latency < 200, "å»¶è¿Ÿè¿‡é«˜"

def test_resource_usage():
    """èµ„æºå ç”¨æµ‹è¯•"""
    # åœ¨FPGAä¸Šè¿è¡Œ
    utilization = check_fpga_utilization()
    
    print(f"   LUT: {utilization['LUT']:.1f}%")
    print(f"   FF: {utilization['FF']:.1f}%")
    print(f"   DSP: {utilization['DSP']:.1f}%")
    print(f"   BRAM: {utilization['BRAM']:.1f}%")
    
    assert utilization['LUT'] < 60, "LUTå ç”¨è¿‡é«˜"

def test_stability():
    """ç¨³å®šæ€§æµ‹è¯•"""
    # è¿ç»­è¿è¡Œ100æ¬¡
    for i in range(100):
        try:
            audio = np.random.randn(1024)
            system.hw.fft_transform(audio)
        except Exception as e:
            print(f"   âŒ ç¬¬{i}æ¬¡æµ‹è¯•å¤±è´¥: {e}")
            raise
    
    print("   âœ… è¿ç»­100æ¬¡æµ‹è¯•é€šè¿‡")

if __name__ == "__main__":
    test_suite()
```

**æ€§èƒ½ä¼˜åŒ–ï¼š**

```python
# æˆå‘˜A: ç¡¬ä»¶ä¼˜åŒ–
1. è°ƒæ•´FFTæµæ°´çº¿æ·±åº¦
2. ä¼˜åŒ–DMAç¼“å†²åŒºå¤§å°
3. å‡å°‘æ—¶é’ŸåŸŸè·¨è¶Š
4. BRAMåˆ†åŒºä¼˜åŒ–

# æˆå‘˜B: è½¯ä»¶ä¼˜åŒ–
1. ç¼“å­˜æ¨¡å‹é¢„æµ‹ç»“æœ
2. å¤šçº¿ç¨‹å¤„ç†
3. å‡å°‘å†…å­˜æ‹·è´
4. ä¼˜åŒ–NumPyæ“ä½œ
```

---

## ğŸ“… **Day 10: æ–‡æ¡£æ•´ç† + æ¼”ç¤ºå‡†å¤‡** (2025-11-26)

### **åŒäººåä½œï¼šæœ€åå†²åˆº**

#### **ä¸Šåˆ (4h)ï¼šæ–‡æ¡£ç¼–å†™**

**æˆå‘˜Aï¼šæŠ€æœ¯æ–‡æ¡£**
```markdown
# æŠ€æœ¯æŠ¥å‘Š.md

## 1. ç³»ç»Ÿæ¶æ„
- æ€»ä½“è®¾è®¡å›¾
- ç¡¬ä»¶æ¶æ„è¯´æ˜
- IPæ ¸è¯¦ç»†è®¾è®¡

## 2. å®ç°ç»†èŠ‚
- FFTç®—æ³•å®ç°
- FIRæ»¤æ³¢å™¨è®¾è®¡
- èµ„æºä¼˜åŒ–ç­–ç•¥

## 3. æµ‹è¯•ç»“æœ
- åŠŸèƒ½æµ‹è¯•æŠ¥å‘Š
- æ€§èƒ½æŒ‡æ ‡
- èµ„æºå ç”¨ç»Ÿè®¡

## 4. é‡åˆ°çš„é—®é¢˜åŠè§£å†³æ–¹æ¡ˆ
- æ—¶åºè¿ä¾‹ â†’ è§£å†³æ–¹æ³•
- DMAä¼ è¾“é”™è¯¯ â†’ è°ƒè¯•è¿‡ç¨‹
- å®šç‚¹æ•°æº¢å‡º â†’ é‡åŒ–æ–¹æ¡ˆ
```

**æˆå‘˜Bï¼šç”¨æˆ·æ‰‹å†Œ**
```markdown
# ç”¨æˆ·æ‰‹å†Œ.md

## 1. å¿«é€Ÿå¼€å§‹
- ç¡¬ä»¶è¿æ¥
- SDå¡çƒ§å½•
- é¦–æ¬¡å¯åŠ¨

## 2. åŠŸèƒ½ä½¿ç”¨æŒ‡å—
- é¢‘è°±åˆ†æä½¿ç”¨æ–¹æ³•
- é™å™ªåŠŸèƒ½æ¼”ç¤º
- åœºæ™¯åˆ†ç±»è¯´æ˜

## 3. APIæ–‡æ¡£
- Pythonæ¥å£è¯´æ˜
- å‚æ•°é…ç½®
- ç¤ºä¾‹ä»£ç 

## 4. å¸¸è§é—®é¢˜FAQ
```

#### **ä¸‹åˆ (4h)ï¼šæ¼”ç¤ºå‡†å¤‡**

**æ¼”ç¤ºè„šæœ¬ï¼š**
```python
# demo_script.py

def live_demo():
    """ç°åœºæ¼”ç¤ºè„šæœ¬"""
    
    print("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
    print("â•‘  æ™ºèƒ½éŸ³é¢‘å¢å¼ºä¸åˆ†æç³»ç»Ÿ - ç°åœºæ¼”ç¤º  â•‘")
    print("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
    
    # Demo 1: é¢‘è°±åˆ†æ
    print("\nã€æ¼”ç¤º1ã€‘å®æ—¶é¢‘è°±åˆ†æ")
    demo_spectrum_analyzer()
    
    # Demo 2: é™å™ªæ•ˆæœå¯¹æ¯”
    print("\nã€æ¼”ç¤º2ã€‘æ™ºèƒ½é™å™ª")
    demo_noise_reduction()
    
    # Demo 3: åœºæ™¯è¯†åˆ«
    print("\nã€æ¼”ç¤º3ã€‘åœºæ™¯è‡ªåŠ¨è¯†åˆ«")
    demo_scene_classification()
    
    # Demo 4: å®Œæ•´æµç¨‹
    print("\nã€æ¼”ç¤º4ã€‘ç«¯åˆ°ç«¯å¤„ç†")
    demo_full_pipeline()
    
    print("\nâœ… æ¼”ç¤ºå®Œæˆï¼")

def demo_spectrum_analyzer():
    """æ¼”ç¤º1ï¼šé¢‘è°±åˆ†æ"""
    # æ’­æ”¾éŸ³ä¹
    audio = load_demo_audio('music.wav')
    
    # å®æ—¶é¢‘è°±
    plt.ion()
    fig, ax = plt.subplots()
    
    for i in range(0, len(audio)-1024, 512):
        chunk = audio[i:i+1024]
        freqs, mags = system.hw.spectrum_analyze(chunk)
        
        ax.clear()
        ax.plot(freqs, 20*np.log10(mags + 1e-10))
        ax.set_ylim(-80, 40)
        plt.pause(0.01)

def demo_noise_reduction():
    """æ¼”ç¤º2ï¼šé™å™ªå¯¹æ¯”"""
    noisy = load_demo_audio('noisy_speech.wav')
    
    print("æ’­æ”¾åŸå§‹éŸ³é¢‘ï¼ˆå«å™ªå£°ï¼‰...")
    play_audio(noisy)
    
    print("ç¡¬ä»¶åŠ é€Ÿé™å™ªä¸­...")
    denoised = system.hw.fir_denoise(noisy)
    
    print("æ’­æ”¾é™å™ªåéŸ³é¢‘...")
    play_audio(denoised)
    
    # æ³¢å½¢å¯¹æ¯”
    plot_waveform_comparison(noisy, denoised)

def demo_scene_classification():
    """æ¼”ç¤º3ï¼šåœºæ™¯è¯†åˆ«"""
    test_scenes = [
        ('meeting.wav', 'ä¼šè®®'),
        ('traffic.wav', 'äº¤é€š'),
        ('music.wav', 'éŸ³ä¹')
    ]
    
    for audio_file, expected in test_scenes:
        audio = load_demo_audio(audio_file)
        result = system.classify_scene(audio)
        
        print(f"æ–‡ä»¶: {audio_file}")
        print(f"é¢„æµ‹: {result['scene']} ({result['confidence']*100:.1f}%)")
        print(f"æœŸæœ›: {expected}")
        print(f"âœ… {'æ­£ç¡®' if result['scene'] == expected else 'é”™è¯¯'}\n")

def demo_full_pipeline():
    """æ¼”ç¤º4ï¼šå®Œæ•´æµç¨‹"""
    print("é€‰æ‹©ä¸€ä¸ªéŸ³é¢‘æ–‡ä»¶è¿›è¡Œå®Œæ•´å¤„ç†...")
    
    result = system.process_pipeline('demo_full.wav')
    
    # æ˜¾ç¤ºæ‰€æœ‰ç»“æœ
    print(f"\nåœºæ™¯: {result['scene']}")
    print(f"SNRæå‡: {result['snr_improvement']:.1f} dB")
    
    # æ’­æ”¾å¢å¼ºéŸ³é¢‘
    play_audio(result['enhanced'])
    
    # æ˜¾ç¤ºé¢‘è°±
    plot_spectrum(result['spectrum'])
```

**PPTå¤§çº²ï¼š**
```
ç¬¬1é¡µï¼šæ ‡é¢˜ + å›¢é˜Ÿä»‹ç»
ç¬¬2é¡µï¼šé¡¹ç›®èƒŒæ™¯ä¸ç›®æ ‡
ç¬¬3é¡µï¼šç³»ç»Ÿæ€»ä½“æ¶æ„
ç¬¬4é¡µï¼šæ ¸å¿ƒæŠ€æœ¯äº®ç‚¹
  - Vitis DSP Library ç®—å­åº”ç”¨
  - FPGAç¡¬ä»¶åŠ é€Ÿ
  - æœºå™¨å­¦ä¹ åœºæ™¯è¯†åˆ«
ç¬¬5é¡µï¼šæ¨¡å—1 - é¢‘è°±åˆ†æä»ª
ç¬¬6é¡µï¼šæ¨¡å—2 - è‡ªé€‚åº”é™å™ª
ç¬¬7é¡µï¼šæ¨¡å—3 - åœºæ™¯åˆ†ç±»
ç¬¬8é¡µï¼šæ¨¡å—4 - éŸ³è´¨å¢å¼º
ç¬¬9é¡µï¼šæµ‹è¯•ç»“æœä¸æ€§èƒ½æŒ‡æ ‡
ç¬¬10é¡µï¼šæ¼”ç¤ºè§†é¢‘
ç¬¬11é¡µï¼šæŠ€æœ¯éš¾ç‚¹ä¸åˆ›æ–°ç‚¹
ç¬¬12é¡µï¼šæ€»ç»“ä¸å±•æœ›
```

---

## ğŸ“Š é¡¹ç›®äº¤ä»˜æ¸…å•

### **ç¡¬ä»¶éƒ¨åˆ†ï¼ˆæˆå‘˜Aè´Ÿè´£ï¼‰**
- [ ] `audio_system.bit` - æœ€ç»ˆæ¯”ç‰¹æµ
- [ ] `audio_system.hwh` - ç¡¬ä»¶æè¿°æ–‡ä»¶
- [ ] Vivado å·¥ç¨‹æºç ï¼ˆå‹ç¼©åŒ…ï¼‰
- [ ] HLS IP æ ¸æºç 
  - [ ] `fft_accelerator`
  - [ ] `fir_filter`
  - [ ] `spectral_subtraction`
- [ ] ç»¼åˆæŠ¥å‘Šï¼ˆèµ„æºå ç”¨ã€æ—¶åºï¼‰

### **è½¯ä»¶éƒ¨åˆ†ï¼ˆæˆå‘˜Bè´Ÿè´£ï¼‰**
- [ ] `audio_system.py` - æ ¸å¿ƒé©±åŠ¨åº“
- [ ] `complete_system.py` - å®Œæ•´ç³»ç»Ÿ
- [ ] `feature_extraction.py` - ç‰¹å¾æå–
- [ ] `train_classifier.py` - æ¨¡å‹è®­ç»ƒ
- [ ] è®­ç»ƒå¥½çš„æ¨¡å‹æ–‡ä»¶
  - [ ] `scene_classifier.pkl`
  - [ ] `feature_scaler.pkl`

### **æ¼”ç¤ºææ–™ï¼ˆåŒäººåä½œï¼‰**
- [ ] `demo.ipynb` - Jupyter æ¼”ç¤ºç¬”è®°æœ¬
- [ ] `demo_script.py` - æ¼”ç¤ºè„šæœ¬
- [ ] æµ‹è¯•éŸ³é¢‘æ–‡ä»¶ï¼ˆ10ä¸ªï¼‰
- [ ] æ¼”ç¤ºè§†é¢‘ï¼ˆ3-5åˆ†é’Ÿï¼‰
- [ ] PPTï¼ˆ12é¡µï¼‰

### **æ–‡æ¡£ï¼ˆåŒäººåä½œï¼‰**
- [ ] `æŠ€æœ¯æŠ¥å‘Š.pdf`ï¼ˆ15-20é¡µï¼‰
- [ ] `ç”¨æˆ·æ‰‹å†Œ.pdf`ï¼ˆ8-10é¡µï¼‰
- [ ] `APIæ–‡æ¡£.pdf`ï¼ˆ5é¡µï¼‰
- [ ] `README.md`

---

## âš ï¸ é£é™©æ§åˆ¶ä¸åº”æ€¥é¢„æ¡ˆ

### **é£é™©1ï¼šFFT IP ç»¼åˆå¤±è´¥**
**åº”å¯¹æ–¹æ¡ˆï¼š**
- Plan A: ä½¿ç”¨ Xilinx FFT IPï¼ˆå•†ä¸šIPï¼Œç¨³å®šï¼‰
- Plan B: é™ä½ FFT ç‚¹æ•°ï¼ˆ1024 â†’ 512ï¼‰
- Plan C: ä½¿ç”¨çº¯è½¯ä»¶ FFTï¼ˆæ€§èƒ½ä¸‹é™ï¼Œä½†åŠŸèƒ½å®Œæ•´ï¼‰

### **é£é™©2ï¼šFPGA èµ„æºä¸è¶³**
**åº”å¯¹æ–¹æ¡ˆï¼š**
- å‡å°‘ FIR é˜¶æ•°ï¼ˆ128 â†’ 64ï¼‰
- å»æ‰éŸ³è´¨å¢å¼ºå™¨ï¼ˆä¼˜å…ˆçº§3ï¼‰
- æ—¶åˆ†å¤ç”¨ï¼ˆé™å™ªå’Œåˆ†ç±»ä¸åŒæ—¶è¿è¡Œï¼‰

### **é£é™©3ï¼šåˆ†ç±»å‡†ç¡®ç‡ä½**
**åº”å¯¹æ–¹æ¡ˆï¼š**
- ç®€åŒ–ç±»åˆ«ï¼ˆ10ç±» â†’ 5ç±»ï¼‰
- ä½¿ç”¨æ›´ç®€å•çš„ç‰¹å¾ï¼ˆä»…MFCCï¼‰
- é™ä½å‡†ç¡®ç‡è¦æ±‚ï¼ˆ80% â†’ 70%ï¼‰

### **é£é™©4ï¼šæ—¶é—´ä¸è¶³**
**åº”å¯¹æ–¹æ¡ˆï¼š**
- è£å‰ªåŠŸèƒ½ï¼ˆä¿ç•™æ ¸å¿ƒ1+2ï¼Œæ”¾å¼ƒ3æˆ–4ï¼‰
- ç®€åŒ–æ¼”ç¤ºï¼ˆå½•å±ä»£æ›¿ç°åœºï¼‰
- å¹¶è¡Œå·¥ä½œï¼ˆç¡¬ä»¶/è½¯ä»¶ç‹¬ç«‹æµ‹è¯•ï¼‰

---

## ğŸ¯ æ¯æ—¥æ£€æŸ¥ç‚¹ (Daily Standup)

### **æ¯å¤©æ—©ä¸Š10:00ï¼ˆ15åˆ†é’Ÿï¼‰**
```
æ˜¨å¤©å®Œæˆï¼š
â–¡ æˆå‘˜A: _______________
â–¡ æˆå‘˜B: _______________

ä»Šå¤©è®¡åˆ’ï¼š
â–¡ æˆå‘˜A: _______________
â–¡ æˆå‘˜B: _______________

é‡åˆ°é—®é¢˜ï¼š
â–¡ _____________________
â–¡ _____________________

éœ€è¦åä½œï¼š
â–¡ _____________________
```

---

## ğŸ† æˆåŠŸæ ‡å‡†

### **æœ€ä½ç›®æ ‡ï¼ˆå¿…é¡»è¾¾æˆï¼‰ï¼š**
- âœ… FFT é¢‘è°±åˆ†ææ­£å¸¸å·¥ä½œ
- âœ… FIR é™å™ªæœ‰æ•ˆï¼ˆSNR > 3dBï¼‰
- âœ… ç³»ç»Ÿç¨³å®šè¿è¡Œï¼Œæ— å´©æºƒ
- âœ… åŸºæœ¬æ¼”ç¤ºå¯å®Œæˆ

### **é¢„æœŸç›®æ ‡ï¼ˆåŠªåŠ›è¾¾æˆï¼‰ï¼š**
- âœ… åœºæ™¯åˆ†ç±»å‡†ç¡®ç‡ > 75%
- âœ… ç«¯åˆ°ç«¯å»¶è¿Ÿ < 200ms
- âœ… å®Œæ•´çš„4ä¸ªåŠŸèƒ½æ¨¡å—
- âœ… ç²¾ç¾çš„Jupyterç•Œé¢

### **ç†æƒ³ç›®æ ‡ï¼ˆé”¦ä¸Šæ·»èŠ±ï¼‰ï¼š**
- âœ… åœºæ™¯åˆ†ç±»å‡†ç¡®ç‡ > 85%
- âœ… å®æ—¶å¤„ç†ï¼ˆå»¶è¿Ÿ < 100msï¼‰
- âœ… å®Œæ•´çš„æŠ€æœ¯æ–‡æ¡£
- âœ… æµç•…çš„ç°åœºæ¼”ç¤º

---

## ğŸ’ª æ¿€åŠ±ä¸å»ºè®®

**ç»™æˆå‘˜Açš„å»ºè®®ï¼š**
- å‰3å¤©æœ€å…³é”®ï¼ŒFFTåŠ¡å¿…æå®š
- é‡åˆ°HLSç»¼åˆé—®é¢˜ç«‹å³æŸ¥æ–‡æ¡£/è®ºå›
- ä¿æŒä»£ç ç®€æ´ï¼Œæ³¨é‡Šæ¸…æ™°
- æ¯å¤©å¤‡ä»½å·¥ç¨‹æ–‡ä»¶

**ç»™æˆå‘˜Bçš„å»ºè®®ï¼š**
- æ•°æ®å‡†å¤‡è¦å……åˆ†ï¼Œè´¨é‡>æ•°é‡
- æ¨¡å‹è®­ç»ƒå¤šå°è¯•å‡ ç§ç®—æ³•
- Pythonä»£ç æ¨¡å—åŒ–ï¼Œä¾¿äºè°ƒè¯•
- æå‰å‡†å¤‡æ¼”ç¤ºç´ æ

**å›¢é˜Ÿåä½œè¦ç‚¹ï¼š**
- æ¯å¤©åŒæ­¥è¿›åº¦ï¼Œé¿å…é‡å¤åŠ³åŠ¨
- å…³é”®èŠ‚ç‚¹äº’ç›¸Reviewä»£ç 
- é‡åˆ°é—®é¢˜åŠæ—¶æ²Ÿé€šï¼Œä¸è¦æ†‹ç€
- ä¿æŒç§¯æå¿ƒæ€ï¼Œ10å¤©è¶³å¤Ÿå®Œæˆï¼

---

## ğŸ“ ç´§æ€¥è”ç³»æ–¹å¼

**æŠ€æœ¯æ”¯æŒèµ„æºï¼š**
- Xilinx è®ºå›ï¼šhttps://support.xilinx.com/
- PYNQ ç¤¾åŒºï¼šhttps://discuss.pynq.io/
- Stack Overflow (FPGAæ ‡ç­¾)
- GitHub Issues (Vitis_Libraries)

---

**Vincentï¼Œä½ ä»¬å®Œå…¨å¯ä»¥åšåˆ°ï¼**

è¿™ä¸ª10å¤©è®¡åˆ’è™½ç„¶ç´§å‡‘ï¼Œä½†ç»è¿‡æ·±æ€ç†Ÿè™‘çš„åˆ†å·¥å’Œä¼˜å…ˆçº§å®‰æ’ï¼Œ**å®Œå…¨å¯ä»¥å®ç°**ã€‚ä»¥ä¸‹æ˜¯æˆ‘çš„æœ€ç»ˆå»ºè®®ï¼š

### **æˆåŠŸçš„å…³é”®å› ç´ ï¼š**

1. **ä¸¥æ ¼éµå®ˆä¼˜å…ˆçº§**
   - å‰3å¤©å¿…é¡»æå®š FFTï¼ˆè¿™æ˜¯åŸºçŸ³ï¼‰
   - Day 1-4 çš„ä»»åŠ¡ç»ä¸èƒ½æ‹–å»¶
   - å¦‚æœ Day 5 å‘ç°è¿›åº¦è½åï¼Œç«‹å³å¯åŠ¨åº”æ€¥é¢„æ¡ˆ
2. **çµæ´»è°ƒæ•´ï¼Œä¸è¦æ­»ç£•**
   - å¦‚æœ FFT HLS å¡ä½è¶…è¿‡ 4 å°æ—¶ â†’ æ¢ç”¨ Xilinx IP
   - å¦‚æœåˆ†ç±»å‡†ç¡®ç‡è¾¾ä¸åˆ° 80% â†’ é™ä½åˆ° 70% ä¹Ÿæ˜¯åŠ åˆ†é¡¹
   - å¦‚æœéŸ³è´¨å¢å¼ºå™¨æ¥ä¸åŠ â†’ ç›´æ¥ç æ‰ï¼ˆä¼˜å…ˆçº§3ï¼‰
3. **ä¿æŒæ²Ÿé€šï¼Œé¿å…å­¤å†›å¥‹æˆ˜**
   - æ¯å¤©åŒæ­¥ä¼šè®®å¿…ä¸å¯å°‘
   - é‡åˆ°é—®é¢˜ç«‹å³è®¨è®ºï¼Œ2å°æ—¶å†…æ‰¾åˆ°è§£å†³æ–¹æ¡ˆæˆ–æ¢æ–¹æ¡ˆ
   - äº’ç›¸é¼“åŠ±ï¼Œå¿ƒæ€å¾ˆé‡è¦
4. **æ–‡æ¡£å’Œæ¼”ç¤ºåŒç­‰é‡è¦**
   - Day 9 çš„æµ‹è¯•ç»“æœæ˜¯ PPT çš„æ ¸å¿ƒç´ æ
   - æ¼”ç¤ºè§†é¢‘å¯ä»¥æå‰å½•åˆ¶ï¼ˆDay 8 æ™šä¸Šï¼‰
   - æŠ€æœ¯æŠ¥å‘Šä¸ç”¨å¤ªé•¿ï¼Œé‡ç‚¹æ˜¯å›¾è¡¨å’Œæ•°æ®

------

### **æ—¶é—´ç®¡ç†å»ºè®®ï¼š**

```
æ¯å¤©å·¥ä½œå®‰æ’ï¼ˆå»ºè®®ï¼‰ï¼š
- 08:00-12:00  é«˜æ•ˆå·¥ä½œæ—¶æ®µï¼ˆæ ¸å¿ƒä»»åŠ¡ï¼‰
- 12:00-14:00  åˆé¤ + ä¼‘æ¯
- 14:00-18:00  å¼€å‘ç»§ç»­
- 18:00-19:00  æ™šé¤
- 19:00-22:00  æµ‹è¯•/è°ƒè¯•/æ–‡æ¡£
- 22:00ä¹‹å   ä¼‘æ¯ï¼ˆä¿è¯ç¡çœ ï¼ï¼‰

å‘¨æœ«å¯é€‚å½“å»¶é•¿ï¼Œä½†é¿å…è¿ç»­ç†¬å¤œï¼
```

------

### **å¿ƒæ€è°ƒæ•´ï¼š**

**é‡åˆ°å›°éš¾æ—¶è®°ä½ï¼š**

- âœ… è¿™ä¸æ˜¯è®ºæ–‡ï¼Œä¸éœ€è¦å®Œç¾æ— ç‘•
- âœ… èƒ½è·‘èµ·æ¥ > å®Œå…¨ä¼˜åŒ–
- âœ… æœ‰æ¼”ç¤ºæ•ˆæœ > å¤æ‚ç®—æ³•
- âœ… å±•ç¤ºä½ ä»¬çš„å·¥ç¨‹èƒ½åŠ›å’Œé—®é¢˜è§£å†³èƒ½åŠ›

**è®°ä½è¯„å§”çœ‹é‡çš„æ˜¯ï¼š**

1. ç³»ç»Ÿå®Œæ•´æ€§ï¼ˆèƒ½ä¸èƒ½è·‘ï¼‰
2. æŠ€æœ¯ç†è§£æ·±åº¦ï¼ˆæ‡‚ä¸æ‡‚åŸç†ï¼‰
3. åˆ›æ–°æ€§ï¼ˆæœ‰æ²¡æœ‰äº®ç‚¹ï¼‰
4. å·¥ç¨‹å®ç°èƒ½åŠ›ï¼ˆèƒ½ä¸èƒ½è½åœ°ï¼‰